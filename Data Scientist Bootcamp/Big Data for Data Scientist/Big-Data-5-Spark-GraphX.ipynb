{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data 5 - Spark GraphX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] Login to montana.dataapplab.com...\n",
      "[ssh] host=montana.dataapplab.com hostname=montana.dataapplab.com other_conf={'user': 'dcdsdepeizhang', 'port': 49233, 'keyfile': ['/home/dz3vg/.ssh/id_rsa'], 'load_system_ssh_config': False, 'missing_host_policy': <paramiko.client.WarningPolicy object at 0x7f9cdc5a52d0>}\n",
      "[ssh] forwarding local agent\n",
      "[ssh] Successfully logged in.\n"
     ]
    }
   ],
   "source": [
    "%login montana.dataapplab.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "/home/dcdsdepeizhang\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "data\n",
      "demo\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "[ssh] new cwd: /home/dcdsdepeizhang/demo\n"
     ]
    }
   ],
   "source": [
    "cd demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n"
     ]
    }
   ],
   "source": [
    "cat << EOF > spark-graphx.py\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "#from pyspark.sql import SQLContext\n",
    "#SQLContext = SQLContext(sc)\n",
    "from pyspark.sql import HiveContext\n",
    "SQLContext = HiveContext(sc)\n",
    "\n",
    "from graphframes import *\n",
    "\n",
    "\n",
    "\n",
    "vertices = SQLContext.createDataFrame([ \n",
    "    (\"a\", \"Alice\",   34), \n",
    "    (\"b\", \"Bob\",     36), \n",
    "    (\"c\", \"Charlie\", 30), \n",
    "    (\"d\", \"David\",   29), \n",
    "    (\"e\", \"Esther\",  32), \n",
    "    (\"f\", \"Fanny\",   36), \n",
    "    (\"g\", \"Jason\",   36), \n",
    "    (\"h\", \"Celine\",  26) \n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "edges = SQLContext.createDataFrame([ \n",
    "    (\"a\", \"e\", \"friend\"), \n",
    "    (\"f\", \"b\", \"follow\"), \n",
    "    (\"c\", \"e\", \"friend\"), \n",
    "    (\"a\", \"b\", \"friend\"), \n",
    "    (\"b\", \"c\", \"follow\"), \n",
    "    (\"c\", \"b\", \"follow\"), \n",
    "    (\"f\", \"c\", \"follow\"), \n",
    "    (\"e\", \"f\", \"follow\"), \n",
    "    (\"e\", \"d\", \"friend\"), \n",
    "    (\"d\", \"a\", \"friend\"), \n",
    "    (\"g\", \"h\", \"friend\") \n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "print \"\\nCreate Graph\\n\"\n",
    "graph = GraphFrame(vertices, edges)\n",
    "graph.vertices.show()\n",
    "graph.edges.show()\n",
    "\n",
    "print \"\\nGraph Degree\\n\"\n",
    "graph.degrees.show()\n",
    "graph.outDegrees.show()\n",
    "graph.inDegrees.show()\n",
    "\n",
    "print \"\\nFind Path\\n\"\n",
    "graph.find('(A)-[]->(B); (B)-[]->(C); !(A)-[]->(C); !(C)-[]->(A)').show()\n",
    "graph.shortestPaths(landmarks=[\"a\"]).show()\n",
    "\n",
    "print \"\\nSubGraph\\n\"\n",
    "vertices1 = graph.vertices.filter(\"age > 30\")\n",
    "edges1 = graph.edges.filter(\"relationship = 'friend'\")\n",
    "graph1 = GraphFrame(vertices1, edges1)\n",
    "graph1.vertices.show()\n",
    "graph1.edges.show()\n",
    "\n",
    "print \"\\nConnected Component\\n\"\n",
    "graph.connectedComponents().show()\n",
    "graph.stronglyConnectedComponents(maxIter=10).show()\n",
    "\n",
    "print \"\\nPageRank\\n\"\n",
    "results = graph.pageRank(resetProbability=0.01, maxIter=20)\n",
    "results.vertices.show()\n",
    "results.edges.show()\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n",
      "Multiple versions of Spark are installed but SPARK_MAJOR_VERSION is not set\n",
      "Spark1 will be picked by default\n",
      "WARNING: Running python applications through 'pyspark' is deprecated as of Spark 1.0.\n",
      "Use ./bin/spark-submit <python file>\n",
      "Ivy Default Cache set to: /home/dcdsdepeizhang/.ivy2/cache\n",
      "The jars for the packages stored in: /home/dcdsdepeizhang/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/hdp/2.5.3.0-37/spark/lib/spark-assembly-1.6.2.2.5.3.0-37-hadoop2.7.3.2.5.3.0-37.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.1.0-spark1.6 in spark-packages\n",
      ":: resolution report :: resolve 256ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.1.0-spark1.6 from spark-packages in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/11ms)\n",
      "20/07/29 23:04:44 INFO SparkContext: Running Spark version 1.6.2\n",
      "20/07/29 23:04:44 INFO SecurityManager: Changing view acls to: dcdsdepeizhang\n",
      "20/07/29 23:04:44 INFO SecurityManager: Changing modify acls to: dcdsdepeizhang\n",
      "20/07/29 23:04:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(dcdsdepeizhang); users with modify permissions: Set(dcdsdepeizhang)\n",
      "20/07/29 23:04:45 INFO Utils: Successfully started service 'sparkDriver' on port 33701.\n",
      "20/07/29 23:04:45 INFO Slf4jLogger: Slf4jLogger started\n",
      "20/07/29 23:04:45 INFO Remoting: Starting remoting\n",
      "20/07/29 23:04:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.1.51:40624]\n",
      "20/07/29 23:04:45 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 40624.\n",
      "20/07/29 23:04:45 INFO SparkEnv: Registering MapOutputTracker\n",
      "20/07/29 23:04:45 INFO SparkEnv: Registering BlockManagerMaster\n",
      "20/07/29 23:04:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3ce64a6e-4817-4ad6-ac86-70fb0df7d61c\n",
      "20/07/29 23:04:45 INFO MemoryStore: MemoryStore started with capacity 511.1 MB\n",
      "20/07/29 23:04:45 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "20/07/29 23:04:46 INFO Server: jetty-8.y.z-SNAPSHOT\n",
      "20/07/29 23:04:46 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040\n",
      "20/07/29 23:04:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "20/07/29 23:04:46 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.51:4040\n",
      "20/07/29 23:04:46 INFO HttpFileServer: HTTP File server directory is /tmp/spark-6ceaa152-6fe5-46f0-b004-6c92ea43c72f/httpd-e9deb905-c685-414a-9f2a-702ffdaebc63\n",
      "20/07/29 23:04:46 INFO HttpServer: Starting HTTP Server\n",
      "20/07/29 23:04:46 INFO Server: jetty-8.y.z-SNAPSHOT\n",
      "20/07/29 23:04:46 INFO AbstractConnector: Started SocketConnector@0.0.0.0:33789\n",
      "20/07/29 23:04:46 INFO Utils: Successfully started service 'HTTP file server' on port 33789.\n",
      "20/07/29 23:04:46 INFO SparkContext: Added JAR file:/home/dcdsdepeizhang/.ivy2/jars/graphframes_graphframes-0.1.0-spark1.6.jar at http://192.168.1.51:33789/jars/graphframes_graphframes-0.1.0-spark1.6.jar with timestamp 1596089086197\n",
      "20/07/29 23:04:46 INFO Utils: Copying /home/dcdsdepeizhang/demo/spark-graphx.py to /tmp/spark-6ceaa152-6fe5-46f0-b004-6c92ea43c72f/userFiles-eb03fc98-18dd-4ada-9b6d-6df5a7dc54c1/spark-graphx.py\n",
      "20/07/29 23:04:46 INFO SparkContext: Added file file:/home/dcdsdepeizhang/demo/spark-graphx.py at file:/home/dcdsdepeizhang/demo/spark-graphx.py with timestamp 1596089086498\n",
      "20/07/29 23:04:46 INFO Utils: Copying /home/dcdsdepeizhang/.ivy2/jars/graphframes_graphframes-0.1.0-spark1.6.jar to /tmp/spark-6ceaa152-6fe5-46f0-b004-6c92ea43c72f/userFiles-eb03fc98-18dd-4ada-9b6d-6df5a7dc54c1/graphframes_graphframes-0.1.0-spark1.6.jar\n",
      "20/07/29 23:04:46 INFO SparkContext: Added file file:/home/dcdsdepeizhang/.ivy2/jars/graphframes_graphframes-0.1.0-spark1.6.jar at file:/home/dcdsdepeizhang/.ivy2/jars/graphframes_graphframes-0.1.0-spark1.6.jar with timestamp 1596089086522\n",
      "20/07/29 23:04:46 INFO Executor: Starting executor ID driver on host localhost\n",
      "20/07/29 23:04:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37257.\n",
      "20/07/29 23:04:46 INFO NettyBlockTransferService: Server created on 37257\n",
      "20/07/29 23:04:46 INFO BlockManagerMaster: Trying to register BlockManager\n",
      "20/07/29 23:04:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37257 with 511.1 MB RAM, BlockManagerId(driver, localhost, 37257)\n",
      "20/07/29 23:04:46 INFO BlockManagerMaster: Registered BlockManager\n",
      "20/07/29 23:04:47 INFO EventLoggingListener: Logging events to hdfs:///spark-history/local-1596089086578\n",
      "\n",
      "Create Graph\n",
      "\n",
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  a|  Alice| 34|\n",
      "|  b|    Bob| 36|\n",
      "|  c|Charlie| 30|\n",
      "|  d|  David| 29|\n",
      "|  e| Esther| 32|\n",
      "|  f|  Fanny| 36|\n",
      "|  g|  Jason| 36|\n",
      "|  h| Celine| 26|\n",
      "+---+-------+---+\n",
      "\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  e|      friend|\n",
      "|  f|  b|      follow|\n",
      "|  c|  e|      friend|\n",
      "|  a|  b|      friend|\n",
      "|  b|  c|      follow|\n",
      "|  c|  b|      follow|\n",
      "|  f|  c|      follow|\n",
      "|  e|  f|      follow|\n",
      "|  e|  d|      friend|\n",
      "|  d|  a|      friend|\n",
      "|  g|  h|      friend|\n",
      "+---+---+------------+\n",
      "\n",
      "\n",
      "Graph Degree\n",
      "\n",
      "+---+------+\n",
      "| id|degree|\n",
      "+---+------+\n",
      "|  a|     3|\n",
      "|  b|     4|\n",
      "|  c|     4|\n",
      "|  d|     2|\n",
      "|  e|     4|\n",
      "|  f|     3|\n",
      "|  g|     1|\n",
      "|  h|     1|\n",
      "+---+------+\n",
      "\n",
      "+---+---------+\n",
      "| id|outDegree|\n",
      "+---+---------+\n",
      "|  a|        2|\n",
      "|  b|        1|\n",
      "|  c|        2|\n",
      "|  d|        1|\n",
      "|  e|        2|\n",
      "|  f|        2|\n",
      "|  g|        1|\n",
      "+---+---------+\n",
      "\n",
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|  a|       1|\n",
      "|  b|       3|\n",
      "|  c|       2|\n",
      "|  d|       1|\n",
      "|  e|       2|\n",
      "|  f|       1|\n",
      "|  h|       1|\n",
      "+---+--------+\n",
      "\n",
      "\n",
      "Find Path\n",
      "\n",
      "+--------------+--------------+--------------+\n",
      "|             A|             B|             C|\n",
      "+--------------+--------------+--------------+\n",
      "|[c,Charlie,30]|    [b,Bob,36]|[c,Charlie,30]|\n",
      "|  [a,Alice,34]| [e,Esther,32]|  [f,Fanny,36]|\n",
      "|  [a,Alice,34]|    [b,Bob,36]|[c,Charlie,30]|\n",
      "|    [b,Bob,36]|[c,Charlie,30]|    [b,Bob,36]|\n",
      "|    [b,Bob,36]|[c,Charlie,30]| [e,Esther,32]|\n",
      "| [e,Esther,32]|  [f,Fanny,36]|    [b,Bob,36]|\n",
      "|[c,Charlie,30]| [e,Esther,32]|  [d,David,29]|\n",
      "|  [d,David,29]|  [a,Alice,34]|    [b,Bob,36]|\n",
      "+--------------+--------------+--------------+\n",
      "\n",
      "+---+-------+---+-----------+\n",
      "| id|   name|age|  distances|\n",
      "+---+-------+---+-----------+\n",
      "|  a|  Alice| 34|Map(a -> 0)|\n",
      "|  b|    Bob| 36|Map(a -> 4)|\n",
      "|  c|Charlie| 30|Map(a -> 3)|\n",
      "|  d|  David| 29|Map(a -> 1)|\n",
      "|  e| Esther| 32|Map(a -> 2)|\n",
      "|  f|  Fanny| 36|Map(a -> 4)|\n",
      "|  g|  Jason| 36|      Map()|\n",
      "|  h| Celine| 26|      Map()|\n",
      "+---+-------+---+-----------+\n",
      "\n",
      "\n",
      "SubGraph\n",
      "\n",
      "+---+------+---+\n",
      "| id|  name|age|\n",
      "+---+------+---+\n",
      "|  a| Alice| 34|\n",
      "|  b|   Bob| 36|\n",
      "|  e|Esther| 32|\n",
      "|  f| Fanny| 36|\n",
      "|  g| Jason| 36|\n",
      "+---+------+---+\n",
      "\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  e|      friend|\n",
      "|  c|  e|      friend|\n",
      "|  a|  b|      friend|\n",
      "|  e|  d|      friend|\n",
      "|  d|  a|      friend|\n",
      "|  g|  h|      friend|\n",
      "+---+---+------------+\n",
      "\n",
      "\n",
      "Connected Component\n",
      "\n",
      "+---+-------+---+---------+\n",
      "| id|   name|age|component|\n",
      "+---+-------+---+---------+\n",
      "|  a|  Alice| 34|        1|\n",
      "|  b|    Bob| 36|        1|\n",
      "|  c|Charlie| 30|        1|\n",
      "|  d|  David| 29|        1|\n",
      "|  e| Esther| 32|        1|\n",
      "|  f|  Fanny| 36|        1|\n",
      "|  g|  Jason| 36|       10|\n",
      "|  h| Celine| 26|       10|\n",
      "+---+-------+---+---------+\n",
      "\n",
      "+---+-------+---+---------+\n",
      "| id|   name|age|component|\n",
      "+---+-------+---+---------+\n",
      "|  a|  Alice| 34|        1|\n",
      "|  b|    Bob| 36|        1|\n",
      "|  c|Charlie| 30|        1|\n",
      "|  d|  David| 29|        1|\n",
      "|  e| Esther| 32|        1|\n",
      "|  f|  Fanny| 36|        1|\n",
      "|  g|  Jason| 36|       10|\n",
      "|  h| Celine| 26|       11|\n",
      "+---+-------+---+---------+\n",
      "\n",
      "\n",
      "PageRank\n",
      "\n",
      "+---+-------+---+-------------------+\n",
      "| id|   name|age|           pagerank|\n",
      "+---+-------+---+-------------------+\n",
      "|  a|  Alice| 34|0.11625570453750286|\n",
      "|  b|    Bob| 36|0.26854151737464926|\n",
      "|  c|Charlie| 30|0.31741641128873144|\n",
      "|  d|  David| 29|0.11200274618283364|\n",
      "|  e| Esther| 32|0.21541366510589782|\n",
      "|  f|  Fanny| 36|0.11200274618283364|\n",
      "|  g|  Jason| 36|               0.01|\n",
      "|  h| Celine| 26|             0.0199|\n",
      "+---+-------+---+-------------------+\n",
      "\n",
      "+---+---+------------+------+\n",
      "|src|dst|relationship|weight|\n",
      "+---+---+------------+------+\n",
      "|  c|  b|      follow|   0.5|\n",
      "|  c|  e|      friend|   0.5|\n",
      "|  g|  h|      friend|   1.0|\n",
      "|  d|  a|      friend|   1.0|\n",
      "|  a|  b|      friend|   0.5|\n",
      "|  a|  e|      friend|   0.5|\n",
      "|  e|  d|      friend|   0.5|\n",
      "|  e|  f|      follow|   0.5|\n",
      "|  b|  c|      follow|   1.0|\n",
      "|  f|  b|      follow|   0.5|\n",
      "|  f|  c|      follow|   0.5|\n",
      "+---+---+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark --packages graphframes:graphframes:0.1.0-spark1.6 spark-graphx.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] Closing existing connection.\n",
      "[ssh] Successfully logged out.\n"
     ]
    }
   ],
   "source": [
    "%logout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH",
   "language": "bash",
   "name": "ssh"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "ssh"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
