{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data 3 - Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] Login to montana.dataapplab.com...\n",
      "[ssh] host=montana.dataapplab.com hostname=montana.dataapplab.com other_conf={'user': 'dcdsdepeizhang', 'port': 49233, 'keyfile': ['/home/dz3vg/.ssh/id_rsa'], 'load_system_ssh_config': False, 'missing_host_policy': <paramiko.client.WarningPolicy object at 0x7fec505833d0>}\n",
      "[ssh] forwarding local agent\n",
      "[ssh] Successfully logged in.\n"
     ]
    }
   ],
   "source": [
    "%login montana.dataapplab.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "/home/dcdsdepeizhang\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "data\n",
      "demo\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "[ssh] new cwd: /home/dcdsdepeizhang/demo\n"
     ]
    }
   ],
   "source": [
    "cd demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n"
     ]
    }
   ],
   "source": [
    "rm /home/dcdsdepeizhang/data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -get hdfs:///user/jason/data/iris.csv /home/dcdsdepeizhang/data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n",
      "151 /home/dcdsdepeizhang/data/iris.csv\n"
     ]
    }
   ],
   "source": [
    "wc -l /home/dcdsdepeizhang/data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n",
      "Id,SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species\n",
      "1,5.1,3.5,1.4,0.2,Iris-setosa\n",
      "2,4.9,3.0,1.4,0.2,Iris-setosa\n",
      "3,4.7,3.2,1.3,0.2,Iris-setosa\n",
      "4,4.6,3.1,1.5,0.2,Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "head -5 /home/dcdsdepeizhang/data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n",
      "20/07/30 21:30:39 INFO fs.TrashPolicyDefault: Moved: 'hdfs://m1.mt.dataapplab.com:8020/user/dcdsdepeizhang/data/iris.csv' to trash at: hdfs://m1.mt.dataapplab.com:8020/user/dcdsdepeizhang/.Trash/Current/user/dcdsdepeizhang/data/iris.csv1596169839459\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -rm hdfs:///user/dcdsdepeizhang/data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -put /home/dcdsdepeizhang/data/iris.csv hdfs:///user/dcdsdepeizhang/data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n",
      "-rw-r--r--   3 dcdsdepeizhang student       5107 2020-07-30 21:30 hdfs:///user/dcdsdepeizhang/data/iris.csv\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -ls hdfs:///user/dcdsdepeizhang/data/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n"
     ]
    }
   ],
   "source": [
    "cat << EOF > spark-sql.py\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "\n",
    "struct = StructType([ \n",
    "    StructField('Id',            IntegerType(), True), \n",
    "    StructField('SepalLengthCm', DoubleType(),  True), \n",
    "    StructField('SepalWidthCm',  DoubleType(),  True), \n",
    "    StructField('PetalLengthCm', DoubleType(),  True), \n",
    "    StructField('PetalWidthCm',  DoubleType(),  True), \n",
    "    StructField('Species',       StringType(),  True)\n",
    "])\n",
    "\n",
    "print \"\\nCreate DataFrame\\n\"\n",
    "df_iris = spark.read.csv('hdfs:///user/dcdsdepeizhang/data/iris.csv', header=True, schema=struct)\n",
    "df_iris.printSchema()\n",
    "df_iris.describe().show()\n",
    "df_iris.show(5)\n",
    "\n",
    "print \"\\nCount\\n\"\n",
    "print df_iris.count()\n",
    "\n",
    "print \"\\nSelect\\n\"\n",
    "df_iris.select(\"PetalWidthCm\").show(5)\n",
    "df_iris.select(df_iris[\"PetalWidthCm\"], df_iris[\"PetalWidthCm\"] + 2).show(5)\n",
    "\n",
    "print \"\\nFilter PetalWidthCm > 0.3\\n\"\n",
    "print df_iris.filter(df_iris[\"PetalWidthCm\"] > 0.3).count()\n",
    "\n",
    "print \"\\nGroup by Species\\n\"\n",
    "df_iris.groupBy(\"Species\").count().show()\n",
    "\n",
    "print \"\\nTemporary View\\n\"\n",
    "df_iris.createOrReplaceTempView(\"temp\")\n",
    "spark.sql(\"SELECT COUNT(*) FROM temp\").show()\n",
    "spark.sql(\"SELECT * FROM temp\").show(5)\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo\n",
      "SPARK_MAJOR_VERSION is set to 2, using Spark2\n",
      "20/07/30 21:30:51 INFO SparkContext: Running Spark version 2.0.0.2.5.3.0-37\n",
      "20/07/30 21:30:51 INFO SecurityManager: Changing view acls to: dcdsdepeizhang\n",
      "20/07/30 21:30:51 INFO SecurityManager: Changing modify acls to: dcdsdepeizhang\n",
      "20/07/30 21:30:51 INFO SecurityManager: Changing view acls groups to: \n",
      "20/07/30 21:30:51 INFO SecurityManager: Changing modify acls groups to: \n",
      "20/07/30 21:30:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dcdsdepeizhang); groups with view permissions: Set(); users  with modify permissions: Set(dcdsdepeizhang); groups with modify permissions: Set()\n",
      "20/07/30 21:30:52 INFO Utils: Successfully started service 'sparkDriver' on port 38519.\n",
      "20/07/30 21:30:52 INFO SparkEnv: Registering MapOutputTracker\n",
      "20/07/30 21:30:52 INFO SparkEnv: Registering BlockManagerMaster\n",
      "20/07/30 21:30:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-085cd39e-9ca4-4b95-895e-c4f689ef252f\n",
      "20/07/30 21:30:52 INFO MemoryStore: MemoryStore started with capacity 366.3 MB\n",
      "20/07/30 21:30:52 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "20/07/30 21:30:52 INFO log: Logging initialized @2759ms\n",
      "20/07/30 21:30:52 INFO Server: jetty-9.2.z-SNAPSHOT\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@12c15a9f{/jobs,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1da7dfaf{/jobs/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@17571bff{/jobs/job,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2d482dd8{/jobs/job/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@35458f4c{/stages,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@16bc64ec{/stages/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@391b0d27{/stages/stage,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@55d1c131{/stages/stage/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4c770b28{/stages/pool,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@39199d4e{/stages/pool/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@588acd7f{/storage,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3095716{/storage/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@77d33214{/storage/rdd,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@255324d{/storage/rdd/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@cbaf64d{/environment,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4542b12b{/environment/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2b6f7805{/executors,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@83f07f{/executors/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5bd076bc{/executors/threadDump,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@bcb4f04{/executors/threadDump/json,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5bb4b128{/static,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@442ba229{/,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1c165986{/api,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4df4866f{/stages/stage/kill,null,AVAILABLE}\n",
      "20/07/30 21:30:52 INFO ServerConnector: Started ServerConnector@5fb145c1{HTTP/1.1}{0.0.0.0:4040}\n",
      "20/07/30 21:30:52 INFO Server: Started @2912ms\n",
      "20/07/30 21:30:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "20/07/30 21:30:52 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.51:4040\n",
      "20/07/30 21:30:53 INFO SparkContext: Added file file:/home/dcdsdepeizhang/demo/spark-sql.py at file:/home/dcdsdepeizhang/demo/spark-sql.py with timestamp 1596169853158\n",
      "20/07/30 21:30:53 INFO Utils: Copying /home/dcdsdepeizhang/demo/spark-sql.py to /tmp/spark-fba74754-dfda-4172-b0db-97c96ab7d8c0/userFiles-71227e33-f4c3-48d6-bcd1-59816b06a859/spark-sql.py\n",
      "20/07/30 21:30:53 INFO Executor: Starting executor ID driver on host localhost\n",
      "20/07/30 21:30:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39662.\n",
      "20/07/30 21:30:53 INFO NettyBlockTransferService: Server created on 192.168.1.51:39662\n",
      "20/07/30 21:30:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.51, 39662)\n",
      "20/07/30 21:30:53 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.51:39662 with 366.3 MB RAM, BlockManagerId(driver, 192.168.1.51, 39662)\n",
      "20/07/30 21:30:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.51, 39662)\n",
      "20/07/30 21:30:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6ac7d78c{/metrics/json,null,AVAILABLE}\n",
      "20/07/30 21:30:54 INFO EventLoggingListener: Logging events to hdfs:///spark2-history/local-1596169853217\n",
      "\n",
      "Create DataFrame\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- SepalLengthCm: double (nullable = true)\n",
      " |-- SepalWidthCm: double (nullable = true)\n",
      " |-- PetalLengthCm: double (nullable = true)\n",
      " |-- PetalWidthCm: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|summary|                Id|     SepalLengthCm|       SepalWidthCm|     PetalLengthCm|      PetalWidthCm|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|  count|               150|               150|                150|               150|               150|\n",
      "|   mean|              75.5| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|\n",
      "| stddev|43.445367992456916|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|\n",
      "|    min|                 1|               4.3|                2.0|               1.0|               0.1|\n",
      "|    max|               150|               7.9|                4.4|               6.9|               2.5|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Count\n",
      "\n",
      "150\n",
      "\n",
      "Select\n",
      "\n",
      "+------------+\n",
      "|PetalWidthCm|\n",
      "+------------+\n",
      "|         0.2|\n",
      "|         0.2|\n",
      "|         0.2|\n",
      "|         0.2|\n",
      "|         0.2|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+------------------+\n",
      "|PetalWidthCm|(PetalWidthCm + 2)|\n",
      "+------------+------------------+\n",
      "|         0.2|               2.2|\n",
      "|         0.2|               2.2|\n",
      "|         0.2|               2.2|\n",
      "|         0.2|               2.2|\n",
      "|         0.2|               2.2|\n",
      "+------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Filter PetalWidthCm > 0.3\n",
      "\n",
      "109\n",
      "\n",
      "Group by Species\n",
      "\n",
      "+---------------+-----+\n",
      "|        Species|count|\n",
      "+---------------+-----+\n",
      "| Iris-virginica|   50|\n",
      "|    Iris-setosa|   50|\n",
      "|Iris-versicolor|   50|\n",
      "+---------------+-----+\n",
      "\n",
      "\n",
      "Temporary View\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     150|\n",
      "+--------+\n",
      "\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SPARK_MAJOR_VERSION=2 spark-submit spark-sql.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] Closing existing connection.\n",
      "[ssh] Successfully logged out.\n"
     ]
    }
   ],
   "source": [
    "%logout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH",
   "language": "bash",
   "name": "ssh"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "ssh"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
