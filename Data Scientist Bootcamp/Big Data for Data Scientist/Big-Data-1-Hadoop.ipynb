{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data 3 - Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] Login to montana.dataapplab.com...\n",
      "[ssh] host=montana.dataapplab.com hostname=montana.dataapplab.com other_conf={'user': 'dcdsdepeizhang', 'port': 49233, 'keyfile': ['/home/dz3vg/.ssh/id_rsa'], 'load_system_ssh_config': False, 'missing_host_policy': <paramiko.client.WarningPolicy object at 0x7f7e8320bbd0>}\n",
      "[ssh] forwarding local agent\n",
      "[ssh] Successfully logged in.\n"
     ]
    }
   ],
   "source": [
    "%login montana.dataapplab.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "/home/dcdsdepeizhang\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "total 8\n",
      "drwxr-xr-x. 3 dcdsdepeizhang student 4096 Jul 30 21:30 data\n",
      "drwxr-xr-x. 4 dcdsdepeizhang student 4096 Jul 30 21:01 demo\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang\n",
      "[ssh] new cwd: /home/dcdsdepeizhang/demo/MapReduce\n"
     ]
    }
   ],
   "source": [
    "cd demo/MapReduce/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n",
      "total 16\n",
      "-rw-r--r--. 1 dcdsdepeizhang student   37 Jul 30 22:59 data.txt\n",
      "-rw-r--r--. 1 dcdsdepeizhang student  539 Jul 30 22:59 mapper.py\n",
      "-rw-r--r--. 1 dcdsdepeizhang student 1041 Jul 30 22:59 reducer.py\n",
      "-rw-r--r--. 1 dcdsdepeizhang student   38 Jul 30 23:00 result.txt\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n"
     ]
    }
   ],
   "source": [
    "cat << EOF > mapper.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into words\n",
    "    words = line.split()\n",
    "    # increase counters\n",
    "    for word in words:\n",
    "        # write the results to STDOUT (standard output);\n",
    "        # what we output here will be the input for the\n",
    "        # Reduce step, i.e. the input for reducer.py\n",
    "        # \n",
    "        # tab-delimited; the trivial word count is 1\n",
    "        print '%s\\t%s' % (word, 1)\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n"
     ]
    }
   ],
   "source": [
    "cat << EOF > reducer.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "\n",
    "current_word = None\n",
    "current_count = 0\n",
    "word = None\n",
    "\n",
    "# input comes from STDIN\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    \n",
    "    # parse the input we got from mapper.py\n",
    "    word, count = line.split('\\t', 1)\n",
    "    \n",
    "    # convert count (currently a string) to int\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        # count was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    "    \n",
    "    # this IF-switch only works because Hadoop sorts map output\n",
    "    # by key (here: word) before it is passed to the reducer\n",
    "    if current_word == word:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_word:\n",
    "            # write result to STDOUT\n",
    "            print '%s\\t%s' % (current_word, current_count)\n",
    "        current_count = count\n",
    "        current_word = word\n",
    " \n",
    "# do not forget to output the last word if needed!\n",
    "if current_word == word:\n",
    "    print '%s\\t%s' % (current_word, current_count)\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n"
     ]
    }
   ],
   "source": [
    "cat << EOF > data.txt\n",
    "this is a test\n",
    "this is a map reduce test\n",
    "test test test test test\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n",
      "total 16\n",
      "-rw-r--r--. 1 dcdsdepeizhang student   67 Jul 30 23:03 data.txt\n",
      "-rw-r--r--. 1 dcdsdepeizhang student  539 Jul 30 23:03 mapper.py\n",
      "-rw-r--r--. 1 dcdsdepeizhang student 1041 Jul 30 23:03 reducer.py\n",
      "-rw-r--r--. 1 dcdsdepeizhang student   38 Jul 30 23:00 result.txt\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n",
      "20/07/30 23:03:42 INFO fs.TrashPolicyDefault: Moved: 'hdfs://m1.mt.dataapplab.com:8020/user/dcdsdepeizhang/data/data.txt' to trash at: hdfs://m1.mt.dataapplab.com:8020/user/dcdsdepeizhang/.Trash/Current/user/dcdsdepeizhang/data/data.txt\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -rm hdfs:///user/dcdsdepeizhang/data/data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -put data.txt hdfs:///user/dcdsdepeizhang/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n",
      "Found 2 items\n",
      "-rw-r--r--   3 dcdsdepeizhang student         67 2020-07-30 23:03 hdfs:///user/dcdsdepeizhang/data/data.txt\n",
      "-rw-r--r--   3 dcdsdepeizhang student       5107 2020-07-30 21:30 hdfs:///user/dcdsdepeizhang/data/iris.csv\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -ls hdfs:///user/dcdsdepeizhang/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n",
      "20/07/30 23:03:53 INFO fs.TrashPolicyDefault: Moved: 'hdfs://m1.mt.dataapplab.com:8020/user/dcdsdepeizhang/temp' to trash at: hdfs://m1.mt.dataapplab.com:8020/user/dcdsdepeizhang/.Trash/Current/user/dcdsdepeizhang/temp\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -rm -r -f hdfs:///user/dcdsdepeizhang/temp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -mkdir hdfs:///user/dcdsdepeizhang/temp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n",
      "20/07/30 23:03:59 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/home/dcdsdepeizhang/demo/MapReduce/mapper.py, /home/dcdsdepeizhang/demo/MapReduce/reducer.py] [/usr/hdp/2.5.3.0-37/hadoop-mapreduce/hadoop-streaming-2.7.3.2.5.3.0-37.jar] /tmp/streamjob4052655824797882179.jar tmpDir=null\n",
      "20/07/30 23:04:02 INFO impl.TimelineClientImpl: Timeline service address: http://m2.mt.dataapplab.com:8188/ws/v1/timeline/\n",
      "20/07/30 23:04:02 INFO client.RMProxy: Connecting to ResourceManager at m2.mt.dataapplab.com/192.168.1.52:8050\n",
      "20/07/30 23:04:02 INFO client.AHSProxy: Connecting to Application History server at m2.mt.dataapplab.com/192.168.1.52:10200\n",
      "20/07/30 23:04:02 INFO impl.TimelineClientImpl: Timeline service address: http://m2.mt.dataapplab.com:8188/ws/v1/timeline/\n",
      "20/07/30 23:04:02 INFO client.RMProxy: Connecting to ResourceManager at m2.mt.dataapplab.com/192.168.1.52:8050\n",
      "20/07/30 23:04:02 INFO client.AHSProxy: Connecting to Application History server at m2.mt.dataapplab.com/192.168.1.52:10200\n",
      "20/07/30 23:04:03 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "20/07/30 23:04:03 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "20/07/30 23:04:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1571167996032_0158\n",
      "20/07/30 23:04:03 INFO impl.YarnClientImpl: Submitted application application_1571167996032_0158\n",
      "20/07/30 23:04:03 INFO mapreduce.Job: The url to track the job: http://m2.mt.dataapplab.com:8088/proxy/application_1571167996032_0158/\n",
      "20/07/30 23:04:03 INFO mapreduce.Job: Running job: job_1571167996032_0158\n",
      "20/07/30 23:04:10 INFO mapreduce.Job: Job job_1571167996032_0158 running in uber mode : false\n",
      "20/07/30 23:04:10 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "20/07/30 23:04:17 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/07/30 23:04:23 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "20/07/30 23:04:23 INFO mapreduce.Job: Job job_1571167996032_0158 completed successfully\n",
      "20/07/30 23:04:23 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=132\n",
      "\t\tFILE: Number of bytes written=438155\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=337\n",
      "\t\tHDFS: Number of bytes written=38\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=14580\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=8278\n",
      "\t\tTotal time spent by all map tasks (ms)=7290\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4139\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=7290\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4139\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=11197440\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8476672\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=4\n",
      "\t\tMap output records=15\n",
      "\t\tMap output bytes=96\n",
      "\t\tMap output materialized bytes=138\n",
      "\t\tInput split bytes=236\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce shuffle bytes=138\n",
      "\t\tReduce input records=15\n",
      "\t\tReduce output records=6\n",
      "\t\tSpilled Records=30\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=258\n",
      "\t\tCPU time spent (ms)=4030\n",
      "\t\tPhysical memory (bytes) snapshot=2453499904\n",
      "\t\tVirtual memory (bytes) snapshot=10237923328\n",
      "\t\tTotal committed heap usage (bytes)=2330460160\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=101\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=38\n",
      "20/07/30 23:04:23 INFO streaming.StreamJob: Output directory: /user/dcdsdepeizhang/temp/result\n"
     ]
    }
   ],
   "source": [
    "hadoop jar /usr/hdp/2.5.3.0-37/hadoop-mapreduce/hadoop-streaming-2.7.3.2.5.3.0-37.jar \\\n",
    "-file /home/dcdsdepeizhang/demo/MapReduce/mapper.py -mapper /home/dcdsdepeizhang/demo/MapReduce/mapper.py \\\n",
    "-file /home/dcdsdepeizhang/demo/MapReduce/reducer.py -reducer /home/dcdsdepeizhang/demo/MapReduce/reducer.py \\\n",
    "-input /user/dcdsdepeizhang/data/data.txt -output /user/dcdsdepeizhang/temp/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n",
      "Found 2 items\n",
      "-rw-r--r--   3 dcdsdepeizhang student          0 2020-07-30 23:04 hdfs:///user/dcdsdepeizhang/temp/result/_SUCCESS\n",
      "-rw-r--r--   3 dcdsdepeizhang student         38 2020-07-30 23:04 hdfs:///user/dcdsdepeizhang/temp/result/part-00000\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -ls hdfs:///user/dcdsdepeizhang/temp/result/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n"
     ]
    }
   ],
   "source": [
    "#hdfs dfs -get hdfs:///user/dcdsdepeizhang/temp/result/part-00000 result.txt\n",
    "hdfs dfs -getmerge hdfs:///user/dcdsdepeizhang/temp/result/ result.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] host = montana.dataapplab.com, cwd = /home/dcdsdepeizhang/demo/MapReduce\n",
      "a\t2\n",
      "is\t2\n",
      "map\t1\n",
      "reduce\t1\n",
      "test\t7\n",
      "this\t2\n"
     ]
    }
   ],
   "source": [
    "head -20 result.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ssh] Closing existing connection.\n",
      "[ssh] Successfully logged out.\n"
     ]
    }
   ],
   "source": [
    "%logout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH",
   "language": "bash",
   "name": "ssh"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "ssh"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
